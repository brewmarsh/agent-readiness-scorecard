import os

def generate_markdown_report(results):
    """Generates a Markdown report from the analysis results based on the new Agent Readiness spec."""
    final_score = results["final_score"]
    file_results = results["file_results"]
    profile = results["profile"]
    agent_name = results["agent"]

    # --- 1. Executive Summary ---
    summary = f"# Agent Scorecard Report\n\n"
    summary += f"**Target Agent Profile:** {agent_name.upper()}\n"
    summary += f"**Description:** {profile['description']}\n\n"
    summary += f"## Final Score: {final_score:.1f}/100\n\n"

    if final_score >= 70:
        summary += "‚úÖ **Status: PASSED** - This codebase is Agent-Ready.\n\n"
    else:
        summary += "‚ùå **Status: FAILED** - This codebase needs improvement for AI Agents.\n\n"

    if results["missing_docs"]:
        summary += "### ‚ö†Ô∏è Missing Critical Documentation\n"
        for doc in results["missing_docs"]:
            summary += f"- `{doc}` (-15 pts)\n"
        summary += "\n"

    # --- 2. Top Refactoring Targets (ACL) ---
    targets = "## üéØ Top Refactoring Targets (Agent Cognitive Load)\n\n"
    targets += "ACL = Complexity + (Lines of Code / 20). Target: ACL <= 10.\n\n"

    all_functions = []
    for f_res in file_results:
        for m in f_res.get("function_metrics", []):
            all_functions.append({**m, "file": f_res["file"]})

    # Sort by ACL descending
    top_acl = sorted(all_functions, key=lambda x: x['acl'], reverse=True)[:10]

    if top_acl:
        targets += "| Function | File | ACL | Status |\n"
        targets += "|----------|------|-----|--------|\n"
        for fn in top_acl:
            if fn['acl'] > 10:
                status = "üî¥ Red" if fn['acl'] > 20 else "üü° Yellow"
                targets += f"| `{fn['name']}` | `{fn['file']}` | {fn['acl']:.1f} | {status} |\n"
        targets += "\n"
    else:
        targets += "‚úÖ No functions with high cognitive load found.\n\n"

    # --- 3. Type Safety Index ---
    types_section = "## üõ°Ô∏è Type Safety Index\n\n"
    types_section += "Target: >90% of functions must have explicit type signatures.\n\n"

    types_section += "| File | Type Safety Index | Status |\n"
    types_section += "| :--- | :---------------: | :----- |\n"
    for res in file_results:
        status = "‚úÖ" if res["type_coverage"] >= 90 else "‚ùå"
        types_section += f"| {res['file']} | {res['type_coverage']:.0f}% | {status} |\n"
    types_section += "\n"

    # --- 4. Agent Prompts ---
    prompts = "## ü§ñ Agent Prompts for Remediation\n\n"

    problematic_files = [f for f in file_results if f["score"] < 90]

    for f_res in problematic_files:
        file_path = f_res["file"]
        file_issues = []

        red_functions = [m for m in f_res["function_metrics"] if m["acl"] > 20]
        yellow_functions = [m for m in f_res["function_metrics"] if 10 < m["acl"] <= 20]

        if red_functions:
            fn_names = ", ".join([f"`{m['name']}`" for m in red_functions])
            file_issues.append(f"- **Critical ACL**: Functions {fn_names} have Red ACL (>20). Prompt: 'Refactor functions in `{file_path}` with high cognitive load to bring ACL below 10. Split complex logic and reduce function length.'")

        if f_res["type_coverage"] < 90:
             file_issues.append(f"- **Type Safety**: Coverage is {f_res['type_coverage']:.0f}%. Prompt: 'Add explicit type signatures to all functions in `{file_path}` to meet the 90% Type Safety Index requirement.'")

        if file_issues:
            prompts += f"### File: `{file_path}`\n"
            prompts += "\n".join(file_issues) + "\n\n"

    if not problematic_files:
        prompts += "‚úÖ Codebase is optimized for AI Agents. No immediate prompts needed.\n\n"

    # --- 5. File Analysis Table ---
    table = "### üìÇ Full File Analysis\n\n"
    table += "| File | Score | Issues |\n"
    table += "| :--- | :---: | :--- |\n"
    for res in file_results:
        status = "‚úÖ" if res["score"] >= 70 else "‚ùå"
        table += f"| {res['file']} | {res['score']} {status} | {res['issues']} |\n"

    return summary + targets + types_section + prompts + "\n" + table + "\n---\n*Generated by Agent-Scorecard*"

def generate_advisor_report(stats, dependency_stats, entropy_stats, cycles):
    """Generates a detailed Advisor Report based on Agent Physics."""

    report = "# üß† Agent Advisor Report\n\n"
    report += "Analysis based on the **Physics of Agent-Code Interaction**.\n\n"

    # --- 1. Agent Cognitive Load (ACL) ---
    report += "## 1. Agent Cognitive Load (ACL)\n"
    report += "Agents have a limited reasoning budget. High ACL burns tokens on logic instead of task execution.\n"
    report += "*Formula: ACL = Complexity + (LOC / 20)*\n\n"

    high_acl_files = [s for s in stats if s.get('acl', 0) > 15]
    high_acl_files.sort(key=lambda x: x.get('acl', 0), reverse=True)

    if high_acl_files:
        report += "### üö® Hallucination Zones (ACL > 15)\n"
        report += "These files are too complex for reliable agent reasoning.\n\n"
        report += "| File | ACL | Complexity | LOC |\n"
        report += "|---|---|---|---|\n"
        for s in high_acl_files:
            report += f"| `{s['file']}` | **{s['acl']:.1f}** | {s['complexity']:.1f} | {s['loc']} |\n"
    else:
        report += "‚úÖ No Hallucination Zones detected. Code is within reasoning limits.\n"
    report += "\n"

    # --- 2. Dependency Entanglement ---
    report += "## 2. Dependency Entanglement\n"
    report += "Complex graphs confuse agent planning capabilities.\n\n"

    # God Modules
    god_modules = {k: v for k, v in dependency_stats.items() if v > 50}
    if god_modules:
        report += "### üï∏ God Modules (Inbound Imports > 50)\n"
        report += "These files appear too often in the context window.\n\n"
        report += "| File | Inbound Refs |\n"
        report += "|---|---|\n"
        sorted_gods = sorted(god_modules.items(), key=lambda x: x[1], reverse=True)
        for k, v in sorted_gods:
             report += f"| `{k}` | {v} |\n"
    else:
         report += "‚úÖ No God Modules detected.\n"
    report += "\n"

    # Circular Dependencies
    if cycles:
        report += "### üîÑ Circular Dependencies\n"
        report += "Infinite recursion risks during planning.\n\n"
        for cycle in cycles:
             report += f"- {' -> '.join(cycle)} -> {cycle[0]}\n"
    else:
        report += "‚úÖ No Circular Dependencies detected.\n"
    report += "\n"

    # --- 3. Context Economics ---
    report += "## 3. Context Economics\n"
    report += "Optimizing the retrieval and context window budget.\n\n"

    if entropy_stats:
        report += "### üìÇ Directory Entropy (Files > 50)\n"
        report += "Large directories confuse retrieval tools.\n\n"
        report += "| Directory | File Count |\n"
        report += "|---|---|\n"
        sorted_entropy = sorted(entropy_stats.items(), key=lambda x: x[1], reverse=True)
        for k, v in sorted_entropy:
            report += f"| `{k}/` | {v} |\n"
    else:
        report += "‚úÖ Directory entropy is low.\n"

    return report

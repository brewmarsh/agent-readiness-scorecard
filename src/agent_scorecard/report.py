import os

def generate_markdown_report(results):
    """Generates a Markdown report from the analysis results."""
    final_score = results["final_score"]
    file_results = results["file_results"]
    profile = results["profile"]
    agent_name = results["agent"]

    # --- 1. Executive Summary ---
    summary = f"# Agent Scorecard Report\n\n"
    summary += f"**Target Agent Profile:** {agent_name.upper()}\n"
    summary += f"**Description:** {profile['description']}\n\n"
    summary += f"## Final Score: {final_score:.1f}/100\n\n"

    if final_score >= 70:
        summary += "‚úÖ **Status: PASSED** - This codebase is Agent-Ready.\n\n"
    else:
        summary += "‚ùå **Status: FAILED** - This codebase needs improvement for AI Agents.\n\n"

    if results["missing_docs"]:
        summary += "### ‚ö†Ô∏è Missing Critical Documentation\n"
        for doc in results["missing_docs"]:
            summary += f"- `{doc}` (-15 pts)\n"
        summary += "\n"

    # --- 2. Refactoring Targets ---
    targets = "## üéØ Top Refactoring Targets\n\n"

    # Sort files by offender categories
    top_complexity = sorted(file_results, key=lambda x: x['complexity'], reverse=True)[:3]
    top_loc = sorted(file_results, key=lambda x: x['loc'], reverse=True)[:3]
    top_types = sorted(file_results, key=lambda x: x['type_coverage'])[:3]

    targets += "| Category         | File Path        | Value      |\n"
    targets += "|------------------|------------------|------------|\n"

    for s in top_complexity:
        if s['complexity'] > profile['max_complexity']:
            targets += f"| Complexity       | {s['file']}      | {s['complexity']:.1f}      |\n"
    for s in top_loc:
        if s['loc'] > profile['max_loc']:
            targets += f"| Lines of Code    | {s['file']}      | {s['loc']}        |\n"
    for s in top_types:
        if s['type_coverage'] < profile['min_type_coverage']:
            targets += f"| Type Coverage    | {s['file']}      | {s['type_coverage']:.0f}%      |\n"
    targets += "\n"

    # --- 3. Agent Prompts ---
    prompts = "## ü§ñ Agent Prompts\n\n"
    unique_files = {s['file'] for s in top_complexity + top_loc + top_types}

    for file_path in sorted(unique_files):
        file_stats = next(s for s in file_results if s['file'] == file_path)
        file_issues = []

        if file_stats['complexity'] > profile['max_complexity']:
             file_issues.append(f"- **Complexity**: Score is {file_stats['complexity']:.1f}. Prompt: 'Refactor `{file_path}` to reduce cyclomatic complexity below {profile['max_complexity']}. Focus on splitting large functions.'")

        if file_stats['loc'] > profile['max_loc']:
             file_issues.append(f"- **Length**: LOC is {file_stats['loc']}. Prompt: 'Reduce the lines of code in `{file_path}` below {profile['max_loc']}. Consider moving helper functions to other modules.'")

        if file_stats['type_coverage'] < profile['min_type_coverage']:
             file_issues.append(f"- **Typing**: Coverage is {file_stats['type_coverage']:.0f}%. Prompt: 'Increase type hint coverage in `{file_path}` to over {profile['min_type_coverage']}%. Ensure all function arguments and return values are typed.'")

        if file_issues:
            prompts += f"### File: `{file_path}`\n"
            prompts += "\n".join(file_issues) + "\n\n"

    # --- 4. Documentation Health ---
    docs = "## üìö Documentation Health\n\n"
    if not results["missing_docs"]:
        docs += "‚úÖ All required documentation files found.\n"
    else:
        docs += "‚ùå Missing: " + ", ".join([f"`{d}`" for d in results["missing_docs"]]) + ". Recommended Action: Create these files to provide context for AI agents.\n"

    # --- 5. File Analysis Table ---
    table = "### üìÇ File Analysis\n\n"
    table += "| File | Score | Issues |\n"
    table += "| :--- | :---: | :--- |\n"
    for res in file_results:
        status = "‚úÖ" if res["score"] >= 70 else "‚ùå"
        table += f"| {res['file']} | {res['score']} {status} | {res['issues']} |\n"

    return summary + targets + prompts + docs + "\n" + table + "\n---\n*Generated by Agent-Scorecard*"

def generate_advisor_report(results):
    """Generates a detailed Advisor Report based on Agent Physics (Beta)."""

    report = "# üß† Agent Advisor Report\n\n"
    report += "Analysis based on the **Physics of Agent-Code Interaction**.\n\n"

    # --- 1. Agent Cognitive Load (ACL) ---
    report += "## 1. Agent Cognitive Load (ACL)\n"
    report += "Agents have a limited reasoning budget. High ACL burns tokens on logic instead of task execution.\n"
    report += "*Formula: ACL = Complexity + (LOC / 20)*\n\n"

    stats = results["file_results"]
    high_acl_files = [s for s in stats if s.get('acl', 0) > 15]
    high_acl_files.sort(key=lambda x: x.get('acl', 0), reverse=True)

    if high_acl_files:
        report += "### üö® Hallucination Zones (ACL > 15)\n"
        report += "These files are too complex for reliable agent reasoning.\n\n"
        report += "| File | ACL | Complexity | LOC |\n"
        report += "|---|---|---|---|\n"
        for s in high_acl_files:
            report += f"| `{s['file']}` | **{s['acl']:.1f}** | {s['complexity']:.1f} | {s['loc']} |\n"
    else:
        report += "‚úÖ No Hallucination Zones detected. Code is within reasoning limits.\n"
    report += "\n"

    # --- 2. Dependency Entanglement ---
    report += "## 2. Dependency Entanglement\n"
    report += "Complex graphs confuse agent planning capabilities.\n\n"

    # God Modules
    dependency_stats = results["inbound"]
    god_modules = {k: v for k, v in dependency_stats.items() if v > 50}
    if god_modules:
        report += "### üï∏ God Modules (Inbound Imports > 50)\n"
        report += "These files appear too often in the context window.\n\n"
        report += "| File | Inbound Refs |\n"
        report += "|---|---|\n"
        sorted_gods = sorted(god_modules.items(), key=lambda x: x[1], reverse=True)
        for k, v in sorted_gods:
             report += f"| `{k}` | {v} |\n"
    else:
         report += "‚úÖ No God Modules detected.\n"
    report += "\n"

    # Circular Dependencies
    cycles = results["cycles"]
    if cycles:
        report += "### üîÑ Circular Dependencies\n"
        report += "Infinite recursion risks during planning.\n\n"
        for cycle in cycles:
             report += f"- {' -> '.join(cycle)} -> {cycle[0]}\n"
    else:
        report += "‚úÖ No Circular Dependencies detected.\n"
    report += "\n"

    # --- 3. Context Economics ---
    report += "## 3. Context Economics\n"
    report += "Optimizing the retrieval and context window budget.\n\n"

    entropy_stats = results["entropy"]
    if entropy_stats["warning"]:
        report += "### üìÇ Directory Entropy Warning\n"
        report += f"Average files per directory: {entropy_stats['avg_files']:.1f} (Threshold: 15)\n\n"
    else:
        report += f"‚úÖ Directory entropy is low ({entropy_stats['avg_files']:.1f} files/dir).\n\n"

    tokens = results["tokens"]
    if tokens["alert"]:
        report += "### ‚ö†Ô∏è Critical Context Token Alert\n"
        report += f"Total critical tokens: {tokens['token_count']:,} (Alert Threshold: 32,000)\n\n"
    else:
        report += f"‚úÖ Critical context size is manageable ({tokens['token_count']:,} tokens).\n\n"

    return report
